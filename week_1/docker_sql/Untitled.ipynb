{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9f3787-8c4d-4b36-a35a-4b86f44805f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-10T07:42:45.196385Z",
     "start_time": "2025-04-10T07:42:44.710350Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d29a3aaae0fc4da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:21:15.028818Z",
     "start_time": "2025-04-09T20:21:15.003707Z"
    }
   },
   "outputs": [],
   "source": [
    "#we need to generate a connection to postgres using SQLAlchemy\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b0cfbb6-83ef-4f71-a3e4-d8baedde4b79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:21:15.028818Z",
     "start_time": "2025-04-09T20:21:15.003707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7f265d6e0dd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e859adcd0950a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:21:43.388839Z",
     "start_time": "2025-04-09T20:21:43.378782Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#we need a schema to put everything on postgres and pandas is able to create this schema\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mget_schema(df,name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myellow_taxi_data\u001b[39m\u001b[38;5;124m'\u001b[39m, con\u001b[38;5;241m=\u001b[39mengine))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#we need a schema to put everything on postgres and pandas is able to create this schema\n",
    "print(pd.io.sql.get_schema(df,name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24121cf7bf9f1a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:39:08.694278Z",
     "start_time": "2025-04-09T20:39:08.632340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iter = pd.read_csv('yellow_tripdata_2021-01.csv',iterator=True,chunksize=10000)\n",
    "df = next(df_iter)\n",
    "# i want to do this (df.head(n=0)) because i first need to create an empty dataframe with all just the column name\n",
    "# later on we will insert data chunk by chunk\n",
    "df.head(n=0).to_sql('yellow_taxi_data', con=engine,if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff70af0782a2834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:40:48.742Z",
     "start_time": "2025-04-09T20:39:21.859171Z"
    }
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     df = \u001b[38;5;28mnext\u001b[39m(df_iter)\n\u001b[32m      3\u001b[39m     df.to_sql(\u001b[33m'\u001b[39m\u001b[33myellow_taxi_data\u001b[39m\u001b[33m'\u001b[39m, con=engine,if_exists=\u001b[33m'\u001b[39m\u001b[33mappend\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/Python/virtual_envs/data311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1624\u001b[39m, in \u001b[36mTextFileReader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1622\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame:\n\u001b[32m   1623\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1624\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1625\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   1626\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/Python/virtual_envs/data311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1733\u001b[39m, in \u001b[36mTextFileReader.get_chunk\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m   1731\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1732\u001b[39m     size = \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m.nrows - \u001b[38;5;28mself\u001b[39m._currow)\n\u001b[32m-> \u001b[39m\u001b[32m1733\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/Python/virtual_envs/data311/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1704\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1697\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1698\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1699\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1700\u001b[39m     (\n\u001b[32m   1701\u001b[39m         index,\n\u001b[32m   1702\u001b[39m         columns,\n\u001b[32m   1703\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1704\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1705\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1708\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/Python/virtual_envs/data311/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28mself\u001b[39m._reader.read_low_memory(nrows)\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Code/Python/virtual_envs/data311/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:839\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mStopIteration\u001b[39m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    df = next(df_iter)\n",
    "    df.to_sql('yellow_taxi_data', con=engine,if_exists='append')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
